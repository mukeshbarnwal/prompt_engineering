Prompt engineering is a method to engineer your prompts so that you get as accurate the llm output as possible. It can be as simple as 1 liner but as complex as 10 to 15 lines depending on the use case. In general, the bigger the prompts, the more clarity the llm model gets, the better the output is for your use case. For example, let says you have a task to categorise the input text into different categories. Your prompt may be as simple as "I am giving you a text. Identify the category of this text from the list of categories provided here: category1, category2, category3". Also your prompt may be more clear, role-based and descriptive like: "You are an expert in classifying documents. These documents belongs to quality domain that relates to products materials, quality checks and various other things. The text of the document is: {input text here}. You have to categorise the given text into one of following categories {input categories here}. Your results should only be the category and nothing else"

Can you observe the difference between both the prompts?
The first observable difference is that in the second prompt, you are giving a role to your llm model. Assignment of role is important because it tells the model to behave like that. Here I am assiging the model a role of expert in classifier. What it essentially does is that it fetches weights of both expert and classifier and uses these weights to categorise your input text. Thus, it is able to identify the category of your text in an accurate manner. 

The second difference is the detailed manner in which you write the prompt. The description of the domain that your use-case belongs to. In the prompt, it is told that these documents belongs to quality domain. You add here more description about quality domain meaning quality checks of the products, materials, etc.  
